Group {
 name ParticleVelocityProjection
 selected true
 addUserKnob {20 User}
 addUserKnob {26 title_text l "" +STARTLINE T "<font size=\"+5\"> Velocity Projection"}
 addUserKnob {26 about l "" +STARTLINE T "<font style=\"color: #666666;\">v1.0 | <a href=\"https://www.linkedin.com/in/petejans/\" style=\"color: #6786b8;\">Peter Jansen</a>"}
 addUserKnob {26 ""}
 addUserKnob {4 mode M {"screen space" "world space"}}
 addUserKnob {7 amount R 0 2}
 amount 1
 addUserKnob {26 ""}
 addUserKnob {26 how_to l "" +STARTLINE T "<font style=\"color: #666666;\"> Screen space recommended for most use cases! EG: <br>\n1. Create a UV map.<br>\n2. Smear the UV map with RotoPaint.<br>\n3. Use <a href=\"https://github.com/mapoga/nuke-vector-matrix/blob/master/nuke/Convert/STMapToVector2.nk\" style=\"color: #6786b8;\">UV to Vector node</a><br>\n4. Set whitepoint to img width (no black clamp!)<br>\n5. Plug into your vel_img"}
}
 Input {
  inputs 0
  name vel_img
  xpos 750
  ypos 270
  number 2
 }
 Crop {
  box {0 0 {input.width} {input.height}}
  crop false
  name Crop1
  xpos 750
  ypos 305
 }
 Input {
  inputs 0
  name particles
  xpos 491
  ypos 79
 }
 ParticleBlinkScript {
  inputs 2
  kernelFile C:/Users/petes/Documents/Nuke_Blinkscripts/vel_from_image_v003.cpp
  kernelSourceGroup 1
  kernelSource "kernel ParticleExampleKernel : ImageComputationKernel<ePixelWise>\n\{\n\n  Image<eReadWrite> p_velocity;\n  Image<eReadWrite> p_position;\n  Image<eReadWrite> p_conditions;\n  Image<eRead, eAccessRandom, eEdgeConstant> image_vel;\n\n\n    param:  \n        float _amount;\n        float _dt;\n        float4x4 camera_matrix;\n        float focalLength;\n        float horizontalAperture;\n        float nearPlane;\n        float farPlane;\n        float pixel_aspect;\n        int mode;\n\n    local:\n       \n        float4x4 worldToScreen;\n        float4x4 view;\n        int _w, _h;     \n\n    void define() \{\n        defineParam(_amount, \"paAmount\", 0.0f);\n        defineParam(_dt, \"_dt\", 1.0f);\n        defineParam(camera_matrix, \"camera_matrix\", float4x4(1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 1.0f) );\n    \}\n\n  float3 transform( float3 p )\n  \{\n    float4 r = worldToScreen*float4(p.x, p.y, p.z, 1.0);\n    float2 xy = float2(r.x, r.y)/r.w;\n    float depth = r.w;\n    return float3(xy, depth);\n  \}\n\n    void init()\{\n        _w = image_vel.bounds.width();\n        _h = image_vel.bounds.height();\n        float image_aspect = float(_h) / float(_w);\n        float4x4 p, s, t;\n        float farMinusNear = farPlane - nearPlane;\n\n        // projection matrix\n        p = float4x4(\n            2 * focalLength / horizontalAperture, 0, 0, 0,\n            0, 2 * focalLength / horizontalAperture, 0, 0,\n            0, 0, -(farPlane + nearPlane) / farMinusNear, -2 * (farPlane * nearPlane) / farMinusNear,\n            0, 0, -1, 0\n        );\n\n        // Matrix to scale normalised pixel coords into actual pixel coords.\n        float x_scale = float(_w) * 0.5;\n        float y_scale = x_scale *pixel_aspect;\n        s.setIdentity();\n        s.scale(float4(x_scale, y_scale, 1.0f,1.0f));\n\n        // Matrix to translate the projected points into normalised pixel coords\n        t.setIdentity();\n        t.translate(float4(1.0, 1.0 - (1.0 - image_aspect / pixel_aspect), 0.0f, 1.0f));\n\n        view =  camera_matrix;\n        view.invert();\n\n        worldToScreen = s * t * p * view;\n\n    \}\n\n\n\n\n  \n    void process() \{\n\n        // p_velocity() *= (1.0f-_amount*_dt);\n        float3 P = p_position();\n        float3 w2s = transform(P);\n        float2 samplepos = float2(w2s.x, w2s.y);\n        float depth = w2s.z;\n\n        // direct values from image\n        float4 sample_vel = image_vel(samplepos.x, samplepos.y);\n\n\n        // if screen space mode, multiply by depth and transform by camera matrix.\n        if (mode==0)\{       \n            sample_vel *=  depth;\n            sample_vel.w = 0.0;\n            sample_vel = camera_matrix * sample_vel;\n        \}\n\n        p_velocity() += float3(sample_vel.x, sample_vel.y, sample_vel.z) * _amount *_dt ;\n\n    \}\n\};\n"
  name ParticleBlinkScript3
  xpos 491
  ypos 299
  addUserKnob {20 User}
  addUserKnob {7 paAmount l amount}
  paAmount {{parent.amount}}
  addUserKnob {7 focalLength}
  focalLength {{parent.DummyCam2.focal}}
  addUserKnob {7 horizontalAperture}
  horizontalAperture {{parent.DummyCam2.haperture}}
  addUserKnob {7 nearPlane}
  nearPlane {{parent.DummyCam2.near}}
  addUserKnob {7 farPlane}
  farPlane {{parent.DummyCam2.far}}
  addUserKnob {7 pixel_aspect l "pixel aspect"}
  pixel_aspect {{vel_img.pixel_aspect}}
  addUserKnob {41 camera_matrix T DummyCam2.world_matrix}
  addUserKnob {3 mode}
  mode {{parent.mode}}
 }
 Output {
  name Output1
  xpos 491
  ypos 534
 }
 Input {
  inputs 0
  name cam
  xpos 196
  ypos 68
  number 1
 }
 Camera {
  projection_mode {{"\[expression \[value the_cam]projection_mode(\[value the_frame])]"}}
  focal {{"\[expression \[value the_cam]focal(\[value the_frame])]"}}
  haperture {{"\[expression \[value the_cam]haperture(\[value the_frame])]"}}
  vaperture {{"\[expression \[value the_cam]vaperture(\[value the_frame])]"}}
  near {{"\[expression \[value the_cam]near(\[value the_frame])]"}}
  far {{"\[expression \[value the_cam]far(\[value the_frame])]"}}
  win_translate {{"\[expression \[value the_cam]win_translate.u(\[value the_frame])]"} {"\[expression \[value the_cam]win_translate.v(\[value the_frame])]"}}
  win_scale {{"\[expression \[value the_cam]win_scale.u(\[value the_frame])]"} {"\[expression \[value the_cam]win_scale.v(\[value the_frame])]"}}
  winroll {{"\[expression \[value the_cam]winroll(\[value the_frame])]"}}
  focal_point {{"\[expression \[value the_cam]focal_point(\[value the_frame])]"}}
  fstop {{"\[expression \[value the_cam]fstop(\[value the_frame])]"}}
  name DummyCam2
  help "DummyCam by Adrian Pueyo\n\nCamera that apart from the matrices also grabs all the \"Projection\" values from the upstream camera that it's connected to. Turns into a default Camera if no Camera connected. Can also be used inside of groups and gizmos, as many levels deep as you want :D All using live and super fast TCL.\n\nUpdated v1.1: Now grabs the correct frame too (thanks Erwan Leroy for the idea).\n\nadrianpueyo.com, 2019-2020"
  onCreate "n = nuke.thisNode()\nfor k in \[\"projection_mode\",\"focal\",\"haperture\",\"vaperture\",\"near\",\"far\",\"win_translate\",\"win_scale\",\"winroll\",\"focal_point\",\"fstop\"]:\n    n\[k].setFlag(0x0000000010000000)"
  label "\[value \[value the_cam]name]"
  xpos 206
  ypos 292
  addUserKnob {20 DummyCam l Defaults}
  addUserKnob {43 the_cam}
  the_cam "\[\n#DummyCam v1.1. Updated 5 April 2020.\nset starting_point \"this.input0\"\nset default \"this.d_\"\n\n# If cam has no inputs, return the default.\nif \{\[exists \$starting_point]\} \{\n    set x \[node \$starting_point]\n\} \{ \n    return \$default\n\}\n\nset finished 0\nwhile \{\$finished != 1\} \{\n\n    # First look for a Cam or Input or topnode.\n    while \{\[class \$x] != \"Camera2\" && \[class \$x] != \"Camera\" && \[class \$x] != \"Camera3\" && \[class \$x] != \"Camera4\" && \[class \$x] != \"Input\" && \$x != \[topnode \$x]\} \{\n        set x \[node \$x.input0]\n    \}\n\n    # Then, check if node is a cam (and return), and otherwise, if it's an input, see if the parent exists and move to it.\n    if \{\[class \$x]==\"Camera2\"||\[class \$x]==\"Camera3\"||\[class \$x]==\"Camera\"||\[class \$x]==\"Camera4\"\} \{\n        set x \[append x \".\"]\n        return \$x\n    \} \{ \n        if \{ \[class \$x]==\"Input\" \} \{ \n            set inp \"\$x.parent.input\"\n            set inputNum \[value \$x.number]\n            set inp \[append inp \$inputNum]\n            if \{ \[exists \$inp] \} \{\n                set x \[node \$inp]\n            \} \{ \n                set finished 1\n            \}\n        \} \{ \n            set finished 1\n        \}\n    \}\n\}\nreturn \$default\n]"
  addUserKnob {43 the_frame}
  the_frame "\[\nset the_camera \[string trimright \[value the_cam] .]\nif \{\[exists \$the_camera]\} \{\n    return \[value \$the_camera.frame]\n\} \{ \n    return \[frame]\n\}\n]"
  addUserKnob {4 d_projection_mode l projection M {perspective orthographic uv spherical ""}}
  addUserKnob {7 d_focal l "focal length" R 0 100}
  d_focal 49
  addUserKnob {7 d_haperture l "horiz aperture" R 0 50}
  d_haperture 30
  addUserKnob {7 d_vaperture l "vert aperture" R 0 50}
  d_vaperture 18.672
  addUserKnob {7 d_near l near R 0 10}
  d_near 1
  addUserKnob {7 d_far l far R 0 10000}
  d_far 1000
  addUserKnob {30 d_win_translate l "window translate"}
  addUserKnob {30 d_win_scale l "window scale"}
  d_win_scale {1 1}
  addUserKnob {7 d_winroll l "window roll" R 0 45}
  addUserKnob {7 d_focal_point l "focal distance" R 0 10}
  d_focal_point 2
  addUserKnob {7 d_fstop l fstop R 0 30}
  d_fstop 16
  addUserKnob {26 version l " " t "Updated 5 April 2020" T "<span style=\"color:#666\"><br/><b>DummyCam v1.1</b> - <a href=\"http://www.adrianpueyo.com\" style=\"color:#666;text-decoration: none;\">adrianpueyo.com</a>, 2019-2020</span>"}
 }
end_group
